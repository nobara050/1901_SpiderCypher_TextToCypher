{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14120219,"sourceType":"datasetVersion","datasetId":8995669},{"sourceId":14134809,"sourceType":"datasetVersion","datasetId":9007054},{"sourceId":14170668,"sourceType":"datasetVersion","datasetId":9032597},{"sourceId":14187426,"sourceType":"datasetVersion","datasetId":9045637},{"sourceId":14197561,"sourceType":"datasetVersion","datasetId":9053972},{"sourceId":14203154,"sourceType":"datasetVersion","datasetId":9058477},{"sourceId":14224166,"sourceType":"datasetVersion","datasetId":9073941},{"sourceId":14224175,"sourceType":"datasetVersion","datasetId":9073948}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture \n!pip install neo4j\n!pip install func_timeout\n!pip install rouge-score\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:16:53.286213Z","iopub.execute_input":"2025-12-19T14:16:53.286554Z","iopub.status.idle":"2025-12-19T14:17:12.968726Z","shell.execute_reply.started":"2025-12-19T14:16:53.286508Z","shell.execute_reply":"2025-12-19T14:17:12.967814Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from neo4j.exceptions import CypherSyntaxError, Neo4jError, ServiceUnavailable\nfrom pandas.testing import assert_series_equal, assert_frame_equal\nfrom func_timeout import func_timeout, FunctionTimedOut\nfrom rouge_score import rouge_scorer\nfrom collections import Counter\nfrom neo4j import GraphDatabase\nimport pandas as pd\nimport numpy as np\nimport re\nimport os\n\nfrom evaluate import load\nbleu_metric = load(\"bleu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:17:21.083073Z","iopub.execute_input":"2025-12-19T14:17:21.083943Z","iopub.status.idle":"2025-12-19T14:17:53.280537Z","shell.execute_reply.started":"2025-12-19T14:17:21.083912Z","shell.execute_reply":"2025-12-19T14:17:53.279814Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766153856.110683      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766153856.171806      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766153856.683866      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766153856.683902      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766153856.683905      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766153856.683907      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119de7ef56f34bc6ae6fea45bb8ce0e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa34089ec3bf4958aabe0dfd7075384e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127f53975e324233bd13a66b56509f4e"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import logging\nlogging.getLogger(\"neo4j\").setLevel(logging.ERROR)\n\nimport warnings\nwarnings.filterwarnings('ignore', category=UserWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:17:55.625361Z","iopub.execute_input":"2025-12-19T14:17:55.626039Z","iopub.status.idle":"2025-12-19T14:17:55.631278Z","shell.execute_reply.started":"2025-12-19T14:17:55.626000Z","shell.execute_reply":"2025-12-19T14:17:55.630553Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# **Load Data**","metadata":{}},{"cell_type":"code","source":"INPUT_CSV_PATH = \"/kaggle/input/test1row-v2/test.csv\"\nOUTPUT_CSV_PATH = \"/kaggle/working/test.csv\" \nCHECKPOINT_INTERVAL = 100\n\nURI = \"neo4j+s://demo.neo4jlabs.com:7687\"\nDRIVERS_BY_ALIAS = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:17:57.571136Z","iopub.execute_input":"2025-12-19T14:17:57.571866Z","iopub.status.idle":"2025-12-19T14:17:57.575225Z","shell.execute_reply.started":"2025-12-19T14:17:57.571834Z","shell.execute_reply":"2025-12-19T14:17:57.574640Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_input = pd.read_csv(INPUT_CSV_PATH, encoding=\"utf-8-sig\")\nprint(f\"Total rows: {len(df_input)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:17:59.354349Z","iopub.execute_input":"2025-12-19T14:17:59.355069Z","iopub.status.idle":"2025-12-19T14:17:59.384290Z","shell.execute_reply.started":"2025-12-19T14:17:59.355028Z","shell.execute_reply":"2025-12-19T14:17:59.383689Z"}},"outputs":[{"name":"stdout","text":"Total rows: 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# **Driver helper**","metadata":{}},{"cell_type":"code","source":"def extract_driver(alias):\n    if alias.startswith(\"neo4jlabs_demo_db_\"):\n        name = alias.replace(\"neo4jlabs_demo_db_\", \"\")\n        return name, name\n    else:\n        raise ValueError(f\"Unsupported database alias: {alias}\")\n\ndef get_driver(alias):\n    if not alias or pd.isna(alias):\n        raise ValueError(\"Database alias cannot be empty\")\n    \n    if alias in DRIVERS_BY_ALIAS:\n        return DRIVERS_BY_ALIAS[alias]\n    \n    try:\n        username, password = extract_driver(alias)\n        driver = GraphDatabase.driver(URI, auth=(username, password))\n        DRIVERS_BY_ALIAS[alias] = driver\n        # print(f\"[INFO] Created new driver for alias: {alias}\")\n        return driver\n    except Exception as e:\n        # print(f\"[ERROR] Failed to create driver for {alias}: {e}\")\n        raise\n\ndef close_all_drivers():\n    for alias, driver in list(DRIVERS_BY_ALIAS.items()):\n        try:\n            driver.close()\n            # print(f\"[INFO] Closed driver for: {alias}\")\n        except Exception as e:\n            print(f\"[WARN] Error closing driver for {alias}: {e}\")\n    DRIVERS_BY_ALIAS.clear()\n    print(\"[INFO] All drivers closed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:01.392566Z","iopub.execute_input":"2025-12-19T14:18:01.393183Z","iopub.status.idle":"2025-12-19T14:18:01.399333Z","shell.execute_reply.started":"2025-12-19T14:18:01.393154Z","shell.execute_reply":"2025-12-19T14:18:01.398460Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# **Validate/Execution Helper**","metadata":{}},{"cell_type":"code","source":"def explain_cypher(cypher, database_alias):\n    if cypher in [\"error\", None, \"\"] or not cypher.strip():\n        return False\n    \n    if pd.isna(database_alias) or not database_alias:\n        return False\n    \n    try:\n        driver = get_driver(database_alias)\n        with driver.session() as session:\n            session.run(f\"EXPLAIN {cypher}\", timeout=30000)\n        return True\n    except Exception:\n        return False\n\ndef execute_cypher(cypher, database_alias):\n    if cypher in [\"error\", None, \"\"] or not cypher.strip():\n        return False, None, \"Empty query\"\n    \n    if pd.isna(database_alias) or not database_alias:\n        return False, None, \"Invalid database alias\"\n    \n    try:\n        driver = get_driver(database_alias)\n        with driver.session() as session:\n            result = session.run(cypher, timeout=30000)\n            records = result.data()\n        return True, records, None\n        \n    except Exception as e:\n        error_msg = str(e).lower()\n        if 'timeout' in error_msg or 'timed out' in error_msg:\n            return False, None, \"TIMEOUT\"\n        return False, None, str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:03.815654Z","iopub.execute_input":"2025-12-19T14:18:03.816200Z","iopub.status.idle":"2025-12-19T14:18:03.822393Z","shell.execute_reply.started":"2025-12-19T14:18:03.816173Z","shell.execute_reply":"2025-12-19T14:18:03.821732Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# **Comparison Helper**","metadata":{}},{"cell_type":"code","source":"def normalize_cypher_result(data, cypher_query=None):\n    if data is None or (isinstance(data, list) and len(data) == 0):\n        return pd.DataFrame()\n    \n    try:\n        df = pd.DataFrame(data)\n    except Exception:\n        return pd.DataFrame()\n    \n    if df.empty:\n        return df\n    \n    df = df.drop_duplicates()\n    \n    for col in df.columns:\n        try:\n            df[col] = pd.to_numeric(df[col])\n        except (ValueError, TypeError):\n            pass\n    \n    numeric_cols = df.select_dtypes(include=['float64', 'float32', 'float16']).columns\n    if len(numeric_cols) > 0:\n        df[numeric_cols] = df[numeric_cols].round(6)\n    \n    str_cols = df.select_dtypes(include=['object']).columns\n    for col in str_cols:\n        df[col] = df[col].astype(str).str.strip().str.lower()\n    \n    has_order_by = False\n    has_limit = False\n    \n    if cypher_query:\n        has_order_by = bool(re.search(r'\\bORDER BY\\b', cypher_query, re.IGNORECASE))\n        has_limit = bool(re.search(r'\\bLIMIT\\b', cypher_query, re.IGNORECASE))\n    \n    df = df.reindex(sorted(df.columns), axis=1)\n    \n    if not has_order_by and not (has_limit and not has_order_by):\n        try:\n            sort_df = df.copy()\n            for col in sort_df.columns:\n                sort_df[col] = sort_df[col].astype(str)\n            sort_df = sort_df.sort_values(by=list(sort_df.columns))\n            df = df.reindex(sort_df.index)\n            df = df.reset_index(drop=True)\n        except Exception:\n            pass\n    \n    df = df.fillna(-99999)\n    df = df.reset_index(drop=True)\n    \n    return df\n\ndef compare_values_match(df_pred, df_gt):\n    if df_pred.shape != df_gt.shape:\n        return False, 'different_shape'\n    \n    if df_pred.empty and df_gt.empty:\n        return True, 'both_empty'\n    \n    try:\n        df_pred_sorted = df_pred.reindex(sorted(df_pred.columns), axis=1)\n        df_gt_sorted = df_gt.reindex(sorted(df_gt.columns), axis=1)\n        \n        is_equal = np.array_equal(df_pred_sorted.values, df_gt_sorted.values)\n        \n        if is_equal:\n            return True, 'values_match'\n        else:\n            return False, 'different_results'\n    \n    except Exception as e:\n        return False, f'comparison_error_{str(e)[:30]}'\n\ndef smart_subset_df(df_sub, df_super, query_sub=None, query_super=None):\n    if df_sub.empty:\n        return False, [], 'empty_subset'\n    if df_super.empty:\n        return False, [], 'empty_superset'\n    \n    df_sub = df_sub.copy()\n    df_super_temp = df_super.copy()\n    matched_columns = []\n    \n    for col_sub_name in df_sub.columns:\n        col_matched = False\n        for col_super_name in df_super_temp.columns:\n            try:\n                col_sub_values = df_sub[col_sub_name].sort_values().reset_index(drop=True)\n                col_super_values = df_super_temp[col_super_name].sort_values().reset_index(drop=True)\n                assert_series_equal(\n                    col_sub_values, \n                    col_super_values, \n                    check_dtype=False, \n                    check_names=False,\n                    check_exact=False\n                )\n                col_matched = True\n                matched_columns.append(col_super_name)\n                df_super_temp = df_super_temp.drop(columns=[col_super_name])\n                break\n            except (AssertionError, ValueError, TypeError):\n                continue\n        \n        if not col_matched:\n            return False, [], f'no_match_for_column_{col_sub_name}'\n    \n    try:\n        df_sub_norm = normalize_cypher_result(df_sub, query_sub)\n        df_super_matched = df_super[matched_columns].copy()\n        df_super_matched.columns = df_sub.columns\n        df_super_matched_norm = normalize_cypher_result(df_super_matched, query_super)\n        assert_frame_equal(\n            df_sub_norm, \n            df_super_matched_norm, \n            check_dtype=False,\n            check_exact=False\n        )\n        return True, matched_columns, 'subset_match_success'\n    except (AssertionError, ValueError, TypeError) as e:\n        return False, matched_columns, f'subset_values_mismatch_{str(e)[:30]}'\n\ndef check_execution_accuracy(pred_cypher, gt_cypher, database_alias):\n    import sys\n    \n    try:\n        pred_success, pred_data, pred_error = execute_cypher(pred_cypher, database_alias)\n        \n        if pred_error == \"TIMEOUT\":\n            return False, None, None, 'execution_timeout', 'pred_query_timeout'\n        \n        gt_success, gt_data, gt_error = execute_cypher(gt_cypher, database_alias)\n        \n        if gt_error == \"TIMEOUT\":\n            return False, None, None, 'execution_timeout', 'gt_query_timeout'\n        \n        if not pred_success or not gt_success:\n            return False, None, None, 'execution_error', 'query_execution_failed'\n        \n        if pred_data and len(pred_data) > 10000:\n            return False, None, None, 'can_not_execute', f'pred_too_large_{len(pred_data)}_rows'\n        if gt_data and len(gt_data) > 10000:\n            return False, None, None, 'can_not_execute', f'gt_too_large_{len(gt_data)}_rows'\n        \n        pred_size = sys.getsizeof(pred_data) if pred_data else 0\n        gt_size = sys.getsizeof(gt_data) if gt_data else 0\n        \n        if pred_size > 100 * 1024 * 1024:\n            return False, None, None, 'can_not_execute', f'pred_memory_{pred_size//1024//1024}MB'\n        if gt_size > 100 * 1024 * 1024:\n            return False, None, None, 'can_not_execute', f'gt_memory_{gt_size//1024//1024}MB'\n        \n        df_pred = pd.DataFrame(pred_data) if pred_data else pd.DataFrame()\n        df_gt = pd.DataFrame(gt_data) if gt_data else pd.DataFrame()\n        \n        df_pred_norm = normalize_cypher_result(df_pred, pred_cypher)\n        df_gt_norm = normalize_cypher_result(df_gt, gt_cypher)\n        \n        is_values_match, detail = compare_values_match(df_pred_norm, df_gt_norm)\n        \n        if is_values_match:\n            return True, None, None, 'values_match', detail\n        \n        if len(df_pred_norm.columns) < len(df_gt_norm.columns) and len(df_pred_norm) == len(df_gt_norm):\n            is_subset, matched_cols, subset_detail = smart_subset_df(\n                df_pred_norm, df_gt_norm, pred_cypher, gt_cypher\n            )\n            \n            if is_subset:\n                return True, None, None, 'value_subset_match', f'subset_{subset_detail}'\n        \n        return False, None, None, 'different_results', 'no_match'\n    \n    except Exception as e:\n        return False, None, None, 'execution_error', f'unexpected_{str(e)[:30]}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:05.474849Z","iopub.execute_input":"2025-12-19T14:18:05.475483Z","iopub.status.idle":"2025-12-19T14:18:05.495269Z","shell.execute_reply.started":"2025-12-19T14:18:05.475452Z","shell.execute_reply":"2025-12-19T14:18:05.494641Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# **Metrics Helper**","metadata":{}},{"cell_type":"code","source":"def normalize_cypher_metrics(cypher: str) -> str:\n    if not cypher:\n        return \"\"\n    cypher = cypher.strip()\n    cypher = re.sub(r\"'([^']*)'\", r'\"\\1\"', cypher) \n    cypher = cypher.lower()\n    cypher = cypher.rstrip(';')                    \n    cypher = re.sub(r'\\s+', ' ', cypher)           \n    return cypher.strip()\n\ndef normalize_cypher_exectmatch(cypher):\n    if not cypher:\n        return \"\"\n    cypher = cypher.strip()\n    # 1. Convert single quotes to double quotes\n    cypher = re.sub(r\"'([^']*)'\", r'\"\\1\"', cypher)\n    \n    # 2. Lowercase\n    cypher = cypher.lower()\n    \n    # 3. Remove semicolon at end\n    cypher = cypher.rstrip(';').strip()\n    \n    # 4. Remove ALL whitespace (thay vì chuẩn hóa thành 1 space)\n    cypher = re.sub(r'\\s+', '', cypher)\n    \n    return cypher\n\ndef exact_match(pred: str, gt: str) -> bool:\n    return normalize_cypher_exectmatch(pred) == normalize_cypher_exectmatch(gt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:09.916874Z","iopub.execute_input":"2025-12-19T14:18:09.917175Z","iopub.status.idle":"2025-12-19T14:18:09.922990Z","shell.execute_reply.started":"2025-12-19T14:18:09.917149Z","shell.execute_reply":"2025-12-19T14:18:09.922188Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def calculate_metrics(pred_cypher, gt_cypher):\n    metrics = {\n        'exact_match': 0.0,\n        'bleu_score': 0.0,\n        'rouge_l_score': 0.0,\n        'token_f1': 0.0\n    }\n   \n    if pred_cypher in [\"error\", \"time_error\"] or not pred_cypher or not gt_cypher:\n        return metrics\n   \n    try:\n        # Exact match: dùng normalize mạnh\n        metrics['exact_match'] = 1.0 if exact_match(pred_cypher, gt_cypher) else 0.0\n       \n        # Chuẩn hóa nhẹ cho các metric text\n        pred_norm = normalize_cypher_metrics(pred_cypher)\n        gt_norm = normalize_cypher_metrics(gt_cypher)\n       \n        # Tokenize giữ nguyên cấu trúc (dùng regex tách keyword và ký tự đặc biệt)\n        pred_tokens = re.findall(r'\\w+|[^\\w\\s]', pred_norm)\n        gt_tokens = re.findall(r'\\w+|[^\\w\\s]', gt_norm)\n       \n        # Google-Bleu (0-100)\n        if pred_norm.strip() and gt_norm.strip():\n            results = bleu_metric.compute(\n                predictions=[pred_norm],\n                references=[[gt_norm]],    # phải là list of list\n                max_order=4,\n                smooth=True\n            )\n            metrics['bleu_score'] = round(results['bleu'] * 100, 4)\n        \n       \n        # ROUGE-L (dùng trực tiếp trên chuỗi đã normalize nhẹ)\n        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n        rouge_scores = scorer.score(gt_norm, pred_norm)\n        metrics['rouge_l_score'] = round(rouge_scores['rougeL'].fmeasure, 4)\n       \n        # Token F1\n        if pred_tokens and gt_tokens:\n            pred_counter = Counter(pred_tokens)\n            gt_counter = Counter(gt_tokens)\n            common_tokens = sum((pred_counter & gt_counter).values())\n           \n            if common_tokens > 0:\n                precision = common_tokens / len(pred_tokens)\n                recall = common_tokens / len(gt_tokens)\n                token_f1 = 2 * precision * recall / (precision + recall)\n                metrics['token_f1'] = round(token_f1, 4)\n       \n    except Exception as e:\n        print(f\"Error calculating metrics: {e}\")  # để debug nếu cần\n   \n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:11.852567Z","iopub.execute_input":"2025-12-19T14:18:11.852863Z","iopub.status.idle":"2025-12-19T14:18:11.860810Z","shell.execute_reply.started":"2025-12-19T14:18:11.852836Z","shell.execute_reply":"2025-12-19T14:18:11.860037Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **Chạy một dòng**","metadata":{}},{"cell_type":"code","source":"def _evaluate_logic(row):\n    pred_cypher = row['cypher_generated']\n    gt_cypher = row['cypher']\n    database_alias = row['database_reference_alias']\n    question_id = row.name\n    \n    text_metrics = calculate_metrics(pred_cypher, gt_cypher)\n    metrics_str = f\"EM: {text_metrics['exact_match']:.2f} | BLEU: {text_metrics['bleu_score']:.3f} | ROUGE-L: {text_metrics['rouge_l_score']:.3f} | Token-F1: {text_metrics['token_f1']:.3f}\"\n    \n    if pred_cypher == \"error\":\n        print(f\"[ROW {question_id}] Result: llm_error | {metrics_str}\")\n        return {'eval_result': 'llm_error', **text_metrics}\n    \n    if pred_cypher == \"time_error\":\n        print(f\"[ROW {question_id}] Result: llm_timeout | {metrics_str}\")\n        return {'eval_result': 'llm_timeout', **text_metrics}\n    \n    # XỬ LÝ DATABASE_ALIAS RỖNG\n    if pd.isna(database_alias) or not database_alias or str(database_alias).strip() == \"\":\n        print(f\"[ROW {question_id}] Result: no_database_alias | {metrics_str}\")\n        return {'eval_result': 'no_database_alias', **text_metrics}\n    \n    try:\n        is_valid = explain_cypher(pred_cypher, database_alias)\n        if not is_valid:\n            print(f\"[ROW {question_id}] Result: invalid_syntax | {metrics_str}\")\n            return {'eval_result': 'invalid_syntax', **text_metrics}\n    except Exception as e:\n        print(f\"[ROW {question_id}] Result: invalid_syntax | {metrics_str}\")\n        return {'eval_result': 'invalid_syntax', **text_metrics}\n    \n    try:\n        exec_correct, _, _, exec_category, detail = check_execution_accuracy(\n            pred_cypher, gt_cypher, database_alias\n        )\n        print(f\"[ROW {question_id}] Result: {exec_category} | {metrics_str}\")\n        return {'eval_result': exec_category, **text_metrics}\n    except Exception as e:\n        print(f\"[ROW {question_id}] Result: execution_error | {metrics_str}\")\n        return {'eval_result': 'execution_error', **text_metrics}\n\ndef evaluate_func(row):\n    try:\n        result = func_timeout(300, _evaluate_logic, args=(row,))\n        return result\n    except FunctionTimedOut:\n        return {\n            'eval_result': 'evaluation_timeout',\n            'exact_match': 0.0,\n            'bleu_score': 0.0,\n            'rouge_l_score': 0.0,\n            'token_f1': 0.0\n        }\n    except Exception:\n        return {\n            'eval_result': 'evaluation_error',\n            'exact_match': 0.0,\n            'bleu_score': 0.0,\n            'rouge_l_score': 0.0,\n            'token_f1': 0.0\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:14.329189Z","iopub.execute_input":"2025-12-19T14:18:14.329903Z","iopub.status.idle":"2025-12-19T14:18:14.337906Z","shell.execute_reply.started":"2025-12-19T14:18:14.329871Z","shell.execute_reply":"2025-12-19T14:18:14.337317Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# **Chạy batch**","metadata":{}},{"cell_type":"code","source":"def run_evaluation():\n    print(f\"[INFO] Loading data from: {INPUT_CSV_PATH}\")\n    df = pd.read_csv(INPUT_CSV_PATH, encoding='utf-8-sig')\n    print(f\"[INFO] Total rows: {len(df)}\")\n    \n    # Load checkpoint nếu có\n    if os.path.exists(OUTPUT_CSV_PATH):\n        df_result = pd.read_csv(OUTPUT_CSV_PATH, encoding='utf-8-sig')\n        \n        # Kiểm tra dòng nào đã được evaluate\n        processed_mask = df_result['eval_result'].notna()\n        processed_count = processed_mask.sum()\n    else:\n        df_result = df.copy()\n        df_result['eval_result'] = None\n        df_result['exact_match'] = None\n        df_result['bleu_score'] = None\n        df_result['rouge_l_score'] = None\n        df_result['token_f1'] = None\n        processed_mask = pd.Series([False] * len(df))\n    \n    try:\n        for idx in range(len(df)):\n            if processed_mask.iloc[idx]:\n                continue\n            \n            row = df.iloc[idx]\n            result = evaluate_func(row)\n            \n            for key, value in result.items():\n                df_result.at[idx, key] = value\n            \n            if (idx + 1) % CHECKPOINT_INTERVAL == 0:\n                df_result.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n                # print(f\"[CHECKPOINT] Saved at row {idx + 1}\")\n        \n        df_result.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')        \n    finally:\n        close_all_drivers()\n    \n    return df_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:16.957422Z","iopub.execute_input":"2025-12-19T14:18:16.958093Z","iopub.status.idle":"2025-12-19T14:18:16.964230Z","shell.execute_reply.started":"2025-12-19T14:18:16.958064Z","shell.execute_reply":"2025-12-19T14:18:16.963574Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def print_summary_report(df):\n    total_samples = len(df)\n  \n    # Tính số lượng có/không có alias\n    df_with_db = df[df['eval_result'] != 'no_database_alias']\n    total_with_db = len(df_with_db)\n    total_no_db = total_samples - total_with_db\n    \n    # ===================================================================\n    # TỔNG QUAN SỐ LƯỢNG MẪU\n    # ===================================================================\n    print(\"\\n\" + \"=\" * 60)\n    print(\"EVALUATION SUMMARY\")\n    print(\"=\" * 60)\n    print(f\"Total Samples             : {total_samples}\")\n    print(f\"With Database Alias       : {total_with_db}\")\n    print(f\"No Database Alias         : {total_no_db}\")\n    \n    # ===================================================================\n    # 1. EXECUTION ACCURACY (chỉ tính trên các dòng có database_alias)\n    # ===================================================================\n    print(\"\\n\" + \"=\" * 60)\n    print(\"EXECUTION ACCURACY (alias)\")\n    print(\"=\" * 60)\n    \n    if total_with_db > 0:\n        counts = df_with_db['eval_result'].value_counts()\n        \n        # Đếm đầy đủ tất cả các category\n        values_match         = counts.get('values_match', 0)\n        value_subset_match   = counts.get('value_subset_match', 0)\n        different_results    = counts.get('different_results', 0)\n        invalid_syntax       = counts.get('invalid_syntax', 0)\n        llm_error            = counts.get('llm_error', 0)\n        llm_timeout          = counts.get('llm_timeout', 0)\n        execution_timeout    = counts.get('execution_timeout', 0)\n        evaluation_timeout   = counts.get('evaluation_timeout', 0)   # THÊM\n        execution_error      = counts.get('execution_error', 0)\n        evaluation_error     = counts.get('evaluation_error', 0)     # THÊM\n        can_not_execute      = counts.get('can_not_execute', 0)\n        \n        print(f\"Total rows evaluated      : {total_with_db}\")\n        print(\"-\" * 60)\n        \n        # Correct cases\n        print(f\"Correct - Exact Match     : {values_match:4d}/{total_with_db} ({values_match/total_with_db*100:5.1f}%)\")\n        print(f\"Correct - Subset Match    : {value_subset_match:4d}/{total_with_db} ({value_subset_match/total_with_db*100:5.1f}%)\")\n        \n        # Incorrect / Failed\n        print(f\"Incorrect (diff results)  : {different_results:4d}/{total_with_db} ({different_results/total_with_db*100:5.1f}%)\")\n        print(f\"Invalid Syntax            : {invalid_syntax:4d}/{total_with_db} ({invalid_syntax/total_with_db*100:5.1f}%)\")\n        \n        # LLM issues\n        print(f\"LLM Error                 : {llm_error:4d}/{total_with_db} ({llm_error/total_with_db*100:5.1f}%)\")\n        print(f\"LLM Timeout               : {llm_timeout:4d}/{total_with_db} ({llm_timeout/total_with_db*100:5.1f}%)\")\n        \n        # Execution & Evaluation issues\n        print(f\"Execution Timeout         : {execution_timeout:4d}/{total_with_db} ({execution_timeout/total_with_db*100:5.1f}%)\")\n        print(f\"Evaluation Timeout        : {evaluation_timeout:4d}/{total_with_db} ({evaluation_timeout/total_with_db*100:5.1f}%)\")\n        print(f\"Execution Error           : {execution_error:4d}/{total_with_db} ({execution_error/total_with_db*100:5.1f}%)\")\n        print(f\"Evaluation Error          : {evaluation_error:4d}/{total_with_db} ({evaluation_error/total_with_db*100:5.1f}%)\")\n        print(f\"Cannot Execute (large/OOM): {can_not_execute:4d}/{total_with_db} ({can_not_execute/total_with_db*100:5.1f}%)\")\n        \n        # Tính Execution Accuracy chính thức\n        correct_total = values_match + value_subset_match\n        exec_accuracy = correct_total / total_with_db * 100\n        print(\"-\" * 60)\n        print(f\"EXECUTION ACCURACY        : {correct_total:4d}/{total_with_db} ({exec_accuracy:5.2f}%)\")\n        \n        # Verify tổng có khớp không\n        total_counted = (values_match + value_subset_match + different_results +\n                         invalid_syntax + llm_error + llm_timeout +\n                         execution_timeout + evaluation_timeout +\n                         execution_error + evaluation_error + can_not_execute)\n        print(f\"[VERIFY] Sum of categories: {total_counted}/{total_with_db} {'✅' if total_counted == total_with_db else '❌'}\")\n        \n    else:\n        print(\"No rows with database_alias found\")\n    \n    # ===================================================================\n    # 2. TEXT-BASED METRICS (tính trên cả alias + no alias)\n    # ===================================================================\n    print(\"\\n\" + \"=\" * 60)\n    print(\"TEXT-BASED METRICS (alias + no alias)\")\n    print(\"=\" * 60)\n    \n    if all(col in df.columns for col in ['exact_match', 'bleu_score', 'rouge_l_score', 'token_f1']):\n        valid_metrics_df = df.dropna(subset=['exact_match', 'bleu_score', 'rouge_l_score', 'token_f1'])\n        if len(valid_metrics_df) > 0:\n            exact_match_mean = valid_metrics_df['exact_match'].mean()\n            bleu_mean = valid_metrics_df['bleu_score'].mean()\n            rouge_mean = valid_metrics_df['rouge_l_score'].mean()\n            token_f1_mean = valid_metrics_df['token_f1'].mean()\n            exact_match_count = (valid_metrics_df['exact_match'] == 1.0).sum()\n            \n            print(f\"Total rows with metrics   : {len(valid_metrics_df)}/{total_samples}\")\n            print(\"-\" * 60)\n            print(f\"Exact Match               : {exact_match_count}/{len(valid_metrics_df)} ({exact_match_mean*100:6.2f}%)\")\n            print(f\"BLEU Score (avg)          : {bleu_mean:.4f}\")\n            print(f\"ROUGE-L Score (avg)       : {rouge_mean:.4f}\")\n            print(f\"Token-F1 (avg)            : {token_f1_mean:.4f}\")\n            \n            # Breakdown theo category (giữ nguyên như cũ)\n            print(\"\\n\" + \"-\" * 60)\n            print(\"BREAKDOWN BY CATEGORY:\")\n            print(\"-\" * 60)\n            for category in ['values_match', 'value_subset_match', 'different_results', 'invalid_syntax', 'no_database_alias']:\n                category_df = valid_metrics_df[valid_metrics_df['eval_result'] == category]\n                if len(category_df) > 0:\n                    cat_em = category_df['exact_match'].mean()\n                    cat_bleu = category_df['bleu_score'].mean()\n                    cat_rouge = category_df['rouge_l_score'].mean()\n                    cat_token_f1 = category_df['token_f1'].mean()\n                    print(f\"{category:25s} (n={len(category_df):4d}): EM={cat_em:.3f}, BLEU={cat_bleu:.4f}, ROUGE-L={cat_rouge:.4f}, Token-F1={cat_token_f1:.4f}\")\n        else:\n            print(\"No valid metrics found in the dataframe\")\n    else:\n        print(\"Metrics columns not found in the dataframe\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:21.268760Z","iopub.execute_input":"2025-12-19T14:18:21.269340Z","iopub.status.idle":"2025-12-19T14:18:21.282994Z","shell.execute_reply.started":"2025-12-19T14:18:21.269310Z","shell.execute_reply":"2025-12-19T14:18:21.282305Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df_results = run_evaluation()\nprint_summary_report(df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T14:18:24.504604Z","iopub.execute_input":"2025-12-19T14:18:24.505160Z","iopub.status.idle":"2025-12-19T14:18:25.085837Z","shell.execute_reply.started":"2025-12-19T14:18:24.505132Z","shell.execute_reply":"2025-12-19T14:18:25.085220Z"}},"outputs":[{"name":"stdout","text":"[INFO] Loading data from: /kaggle/input/test1row-v2/test.csv\n[INFO] Total rows: 1\n[ROW 0] Result: values_match | EM: 1.00 | BLEU: 100.000 | ROUGE-L: 1.000 | Token-F1: 1.000\n[INFO] All drivers closed.\n\n============================================================\nEVALUATION SUMMARY\n============================================================\nTotal Samples             : 1\nWith Database Alias       : 1\nNo Database Alias         : 0\n\n============================================================\nEXECUTION ACCURACY (alias)\n============================================================\nTotal rows evaluated      : 1\n------------------------------------------------------------\nCorrect - Exact Match     :    1/1 (100.0%)\nCorrect - Subset Match    :    0/1 (  0.0%)\nIncorrect (diff results)  :    0/1 (  0.0%)\nInvalid Syntax            :    0/1 (  0.0%)\nLLM Error                 :    0/1 (  0.0%)\nLLM Timeout               :    0/1 (  0.0%)\nExecution Timeout         :    0/1 (  0.0%)\nEvaluation Timeout        :    0/1 (  0.0%)\nExecution Error           :    0/1 (  0.0%)\nEvaluation Error          :    0/1 (  0.0%)\nCannot Execute (large/OOM):    0/1 (  0.0%)\n------------------------------------------------------------\nEXECUTION ACCURACY        :    1/1 (100.00%)\n[VERIFY] Sum of categories: 1/1 ✅\n\n============================================================\nTEXT-BASED METRICS (alias + no alias)\n============================================================\nTotal rows with metrics   : 1/1\n------------------------------------------------------------\nExact Match               : 1/1 (100.00%)\nBLEU Score (avg)          : 100.0000\nROUGE-L Score (avg)       : 1.0000\nToken-F1 (avg)            : 1.0000\n\n------------------------------------------------------------\nBREAKDOWN BY CATEGORY:\n------------------------------------------------------------\nvalues_match              (n=   1): EM=1.000, BLEU=100.0000, ROUGE-L=1.0000, Token-F1=1.0000\n","output_type":"stream"}],"execution_count":16}]}